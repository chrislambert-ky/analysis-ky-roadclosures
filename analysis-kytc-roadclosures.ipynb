{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is being developed as part of the Code Kentucky Python Data Analyst pathway.<br>\n",
    "\n",
    "Technical Specifications:\n",
    "- Python 3.11.7<br>\n",
    "- Instructions on setting up a Python virtual environment are contained in the README.md<br>\n",
    "- Dependencies are available by running the following command: pip install -r requirements.txt\n",
    "\n",
    "The following Code Kentucky Required Features are contained in the this notebook:<br>\n",
    "- Feature #1 choice: Read multiple data files (JSON, CSV, Excel, etc.)\n",
    "- Feature #2 choice: Clean the data and perform a pandas merge, then calculate some new values based on the new data set.\n",
    "- Feature #3 choice: Make 3 matplotlib (or another plotting library) visualizations to display your data.\n",
    "- Feature #4 choice: Utilize a Python virtual environment and include instructions in your README on how the user should set one up\n",
    "- Feature #5 choice: Annotate my code with markdown cells in Jupyter Notebook, write clear code comments, and have a well-written README.md.\n",
    "\n",
    "I've chosen the following *optional* features (if time allows):\n",
    "- Feature #3 (optional): Tableau and PowerBI visualizations.\n",
    "- Feature #4 (optional): Build a custom data dictionary.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Quantify the impact of road closures based on three metrics:\n",
    "1) Total number of closures<br>\n",
    "2) Frequency of closures<br>\n",
    "3) Duration of closures.<br>\n",
    "\n",
    "These are a few of the sample questions that I hope to answer:<br>\n",
    "1) How many closures occur statewide each year? (Normal bar graph showing count per year?)<br>\n",
    "2) How many road closures occur in each county per year? (Normal bar graph with year as x-axis and count of closures?)<br>\n",
    "3) How often, or how frequently, is a single road being closed due to rainfall? (Horizonatal bar graph with roadname as Y axis or pivot table output?)<br>\n",
    "4) What is the average duration of road closures?\n",
    "\n",
    "Methodology:\n",
    "1) Import/load road closure data directly from hosted web server into Pandas.<br>\n",
    "2) Parse out the Latitude and Longitude by stripping unneeded hyperlink characters.<br>\n",
    "3) Produce standalone latitude and longitude columns/fields, which is preferred for mapping in most BI software.<br>\n",
    "3) Standardize timestamps to assist with calculating duration.<br>\n",
    "4) Modify the duration calculation to show hours as float64, making it easier to use in popular BI tools.<br>\n",
    "5) Summarize the results by year, county, and roadway using record counts and caculated durations.\n",
    "6) If time allows, develop an overall score that takes into consideration the frequency and duration of events.\n",
    "\n",
    "DISCLAIMER:  Results may vary.  In addition to historic data, this notebook is also utilizing current year data.  The data source is updated every 1 hour but only when there are active road closures due to weather related events.\n",
    "\n",
    "-Chris Lambert\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Depending on the version, Pandas displays a deprecation notice about pyarrow.\n",
    "#I have installed the latest pyarrow sepearetly, just in case.\n",
    "#Import Python Libraries / Dependencies\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021 Dataset: Specific notes and findings about the dataset are detailed using in-line comments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze the 2021 dataset.  I prefer to perform the import and cleaning in-memory as opposed to using local files.\n",
    "\n",
    "#Load the 2021 dataset from the web server. \n",
    "df2021=pd.read_csv(\"https://storage.googleapis.com/kytc-its-2020-openrecords/toc/KYTC-TOC-Weather-Closures-Historic-2021.csv\")\n",
    "\n",
    "#Export the 2021 dataset to a csv file as a method of copying the data to the local machine.\n",
    "#This gives me a backup of the file and something to reference. \n",
    "df2021.to_csv(\"KYTC-TOC-Weather-Closures-Historic-2021.csv\", index=False)\n",
    "\n",
    "#After reviewing the data, I noticed that the 'Route_Link' column contains a URL.\n",
    "#The url needs to be cleaned to reveal the latitude and longitude, just in case I need them for mapping.\n",
    "#I assume a strip that essentially performs a find/replace would work here.\n",
    "df2021['Route_Link'] = df2021['Route_Link'].str.replace('https://kytc.maps.arcgis.com/apps/webappviewer/index.html?id=327a38decc8c4e5cb882dc6cd0f9d45d&zoom=14&center=', '')\n",
    "df2021[['longitude','latitude']] = df2021.Route_Link.str.split(\",\",expand=True,)\n",
    "df2021 = df2021.drop('Route_Link', axis=1)\n",
    "\n",
    "#After reviewing the data, I noticed the following issues:\n",
    "#'Reported_On' and 'End_Date' columns contain what looks like different timestamps.\n",
    "#I checked with the data owners this is a known issue.  They are unable to provide additional guidance.\n",
    "#I am proceeding, knowing that my duration calculation may be off by 4 hours\n",
    "#I need to clean that before I can calculate the duration.\n",
    "#I also noticed that the 'Comments' column contains line breaks.\n",
    "df2021['End_Date'] = df2021['End_Date'].str.replace('+00:00', '')\n",
    "df2021['Duration_Default'] = pd.to_datetime(df2021['End_Date']) - pd.to_datetime(df2021['Reported_On'])\n",
    "df2021['Duration_Hours'] = df2021['Duration_Default'].dt.total_seconds() / 3600\n",
    "df2021['Comments'] = df2021['Comments'].replace(r'[\\r\\n]+', ' ', regex=True) #removing line breaks from the comments column.\n",
    "order=['District','County','Route','Road_Name','Begin_MP','End_MP','Comments','Reported_On','End_Date','latitude','longitude','Duration_Default','Duration_Hours']\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#Uncomment the lines below to verify datatypes and review data in dataframe.\n",
    "#print(df2021.dtypes) #verify the datatypes in the dataframe\n",
    "#print(df2021.head(3)) #print the first 3 rows of the dataframe\n",
    "\n",
    "#Export the clean 2021 dataset to a csv file to show progress.\n",
    "df2021.to_csv(\"kytc-closures-2021-clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 Dataset: Specific notes and findings about the dataset are detailed using in-line comments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District                      int64\n",
      "County                       object\n",
      "Route                        object\n",
      "Road_Name                    object\n",
      "Begin_MP                    float64\n",
      "End_MP                      float64\n",
      "Comments                     object\n",
      "Reported_On                  object\n",
      "End_Date                     object\n",
      "latitude                     object\n",
      "longitude                    object\n",
      "Duration_Default    timedelta64[ns]\n",
      "Duration_Hours              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Analyze the 2022 dataset.  I prefer to perform the import and cleaning in-memory as opposed to using local files.\n",
    "\n",
    "#Load the 2022 dataset from the web server.\n",
    "df2022=pd.read_csv(\"https://storage.googleapis.com/kytc-its-2020-openrecords/toc/KYTC-TOC-Weather-Closures-Historic-2022.csv\")\n",
    "\n",
    "#Export the 2022 dataset to a csv file as a method of copying the data to the local machine. \n",
    "df2022.to_csv(\"KYTC-TOC-Weather-Closures-Historic-2022.csv\", index=False)\n",
    "\n",
    "#After reviewing the data, I realized that the 'Route_Link' column contains a different URL from the previous dataset.\n",
    "#The characters in the URL are different and the latitude and longitude are in a different order.\n",
    "df2022['Route_Link'] = df2022['Route_Link'].str.replace('https://goky.ky.gov/?lat=','')\n",
    "df2022['Route_Link'] = df2022['Route_Link'].str.replace('&lng=',',')\n",
    "df2022['Route_Link'] = df2022['Route_Link'].str.replace('&zoom=14','')\n",
    "df2022[['latitude','longitude']] = df2022.Route_Link.str.split(\",\",expand=True,) #removing line breaks from the comments column.\n",
    "df2022 = df2022.drop('Route_Link', axis=1)\n",
    "\n",
    "#After reviewing the data, I noticed that the 'Reported_On' and 'End_Date' columns seem to be the same timestamp.\n",
    "#I need to clean that before I can calculate the duration.\n",
    "#The reported_on time and the end_date are the same timestamps, which is a change from the previous dataset.\n",
    "#Since it will not cause any harm to the data, I am keeping the str.replace.\n",
    "#I also noticed that the 'Comments' column contains line breaks.\n",
    "df2022['End_Date'] = df2022['End_Date'].str.replace('+00:00', '')\n",
    "df2022['Duration_Default'] = pd.to_datetime(df2022['End_Date']) - pd.to_datetime(df2022['Reported_On'])\n",
    "df2022['Duration_Hours'] = df2022['Duration_Default'].dt.total_seconds() / 3600\n",
    "df2022['Comments'] = df2022['Comments'].replace(r'[\\r\\n]+', ' ', regex=True) #removing line breaks from the comments column.\n",
    "\n",
    "\n",
    "#Uncomment the lines below to verify datatypes and review data in dataframe.\n",
    "print(df2022.dtypes) #verify the datatypes in the dataframe\n",
    "#print(df2022.head(3)) #print the first 3 rows of the dataframe\n",
    "\n",
    "#Export the clean 2022 dataset to a csv file to show progress.\n",
    "df2022.to_csv(\"kytc-closures-2022-clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023 Dataset: Specific notes and findings about the dataset are detailed using in-line comments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District                      int64\n",
      "County                       object\n",
      "Route                        object\n",
      "Road_Name                    object\n",
      "Begin_MP                    float64\n",
      "End_MP                      float64\n",
      "Comments                     object\n",
      "Reported_On                  object\n",
      "End_Date                     object\n",
      "latitude                     object\n",
      "longitude                    object\n",
      "Duration_Default    timedelta64[ns]\n",
      "Duration_Hours              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Analyze the 2023 dataset.\n",
    "\n",
    "#The ending characters were incorrectly published and included the roadname in additon to the zoom level.\n",
    "\n",
    "#Load the 2022 dataset from the web server. \n",
    "df2023=pd.read_csv(\"https://storage.googleapis.com/kytc-its-2020-openrecords/toc/KYTC-TOC-Weather-Closures-Historic-2023.csv\")\n",
    "\n",
    "#Export the 2022 dataset to a csv file as a method of copying the data to the local machine. \n",
    "df2023.to_csv(\"KYTC-TOC-Weather-Closures-Historic-2023.csv\", index=False)\n",
    "\n",
    "#After reviewing the data, I noticed that the 'Route_Link' column contains an error in the URL.\n",
    "#This will require some additional work to strip the unwanted values.\n",
    "#The placement of latitude and longitude are consistent between 2022-2024.\n",
    "#The error occurs at the end of the URL, where someone has inserted a route name.\n",
    "#This will require a regex to remove all characters after, and including, the &.\n",
    "df2023['Route_Link'] = df2023['Route_Link'].str.replace('https://goky.ky.gov/?lat=','')\n",
    "df2023['Route_Link'] = df2023['Route_Link'].str.replace('&lng=',',')\n",
    "df2023['Route_Link'] = df2023['Route_Link'].str.replace('&.*', '', regex=True) #Regex was needed to compensate for an output error in the 2023 data.\n",
    "df2023[['latitude','longitude']] = df2023.Route_Link.str.split(\",\",expand=True,)\n",
    "df2023 = df2023.drop('Route_Link', axis=1)\n",
    "\n",
    "#I need to clean that before I can calculate the duration.\n",
    "#The reported_on time and the end_date are the same from the previous dataset.  No changes are needed.\n",
    "#I also noticed that the 'Comments' column contains line breaks.\n",
    "df2023['End_Date'] = df2023['End_Date'].str.replace('+00:00', '')\n",
    "df2023['Duration_Default'] = pd.to_datetime(df2023['End_Date']) - pd.to_datetime(df2023['Reported_On'])\n",
    "df2023['Duration_Hours'] = df2023['Duration_Default'].dt.total_seconds() / 3600\n",
    "df2023['Comments'] = df2023['Comments'].replace(r'[\\r\\n]+', ' ', regex=True) #removing line breaks from the comments column.\n",
    "\n",
    "\n",
    "\n",
    "#Uncomment the lines below to verify datatypes and review data in dataframe.\n",
    "print(df2023.dtypes) #verify the datatypes in the dataframe\n",
    "#print(df2023.head(3)) #print the first 3 rows of the dataframe\n",
    "\n",
    "#Export the clean 2023 dataset to a csv file to show progress.\n",
    "df2023.to_csv(\"kytc-closures-2023-clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2024 Dataset: Specific notes and findings about the dataset are detailed using in-line comments.<br>\n",
    "2024 is the current year of this analysis so this dataset will update ever hour during weather events.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District                      int64\n",
      "County                       object\n",
      "Route                        object\n",
      "Road_Name                    object\n",
      "Begin_MP                    float64\n",
      "End_MP                      float64\n",
      "Comments                     object\n",
      "Reported_On                  object\n",
      "End_Date                     object\n",
      "latitude                     object\n",
      "longitude                    object\n",
      "Duration_Default    timedelta64[ns]\n",
      "Duration_Hours              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Analyze the 2024 dataset.\n",
    "#Since this is 2024, this dataset is updated every 1 hour during weather events.\n",
    "#This will produce different calculations throughout the year.\n",
    "\n",
    "#Load the 2024 dataset from the web server. \n",
    "df2024=pd.read_csv(\"https://storage.googleapis.com/kytc-its-2020-openrecords/toc/KYTC-TOC-Weather-Closures-Historic-2024.csv\")\n",
    "\n",
    "#Export the 2024 dataset to a csv file as a method of copying the data to the local machine. \n",
    "df2024.to_csv(\"KYTC-TOC-Weather-Closures-Historic-2024.csv\", index=False)\n",
    "\n",
    "#The url needs to be cleaned.\n",
    "#The placement of latitude and longitude are consistent between 2022-2024 but the ending of the URL in 2023 forced me to use a regex.\n",
    "df2024['Route_Link'] = df2024['Route_Link'].str.replace('https://goky.ky.gov/?lat=','')\n",
    "df2024['Route_Link'] = df2024['Route_Link'].str.replace('&lng=',',')\n",
    "df2024['Route_Link'] = df2024['Route_Link'].str.replace('&.*', '', regex=True)\n",
    "df2024[['latitude','longitude']] = df2024.Route_Link.str.split(\",\",expand=True,)\n",
    "df2024 = df2024.drop('Route_Link', axis=1)\n",
    "\n",
    "#I need to clean that before I can calculate the duration.\n",
    "#The reported_on time and the end_date are the same timestamps but I'm keeping the strip code in just in case.\n",
    "#I also noticed that the 'Comments' column contains line breaks.\n",
    "df2024['End_Date'] = df2024['End_Date'].str.replace('+00:00', '')\n",
    "df2024['Duration_Default'] = pd.to_datetime(df2023['End_Date']) - pd.to_datetime(df2024['Reported_On'])\n",
    "df2024['Duration_Hours'] = df2024['Duration_Default'].dt.total_seconds() / 3600\n",
    "df2024['Comments'] = df2024['Comments'].replace(r'[\\r\\n]+', ' ', regex=True) #removing line breaks from the comments column.\n",
    "\n",
    "#Uncomment the lines below to verify datatypes and review data in dataframe.\n",
    "print(df2024.dtypes) #verify the datatypes in the dataframe\n",
    "#print(df2024.head(3)) #print the first 3 rows of the dataframe\n",
    "\n",
    "#Export the clean 2023 dataset to a csv file to show progress.\n",
    "df2024.to_csv(\"kytc-closures-2024-clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Dataframes and Create Reporting Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the following dataframes together.\n",
    "#In 2021, the columns are in a slightly different order.\n",
    "\n",
    "#I've developed a column list to force uniformity between the datasets.\n",
    "col_order=['District','County','Route','Road_Name','Begin_MP','End_MP','Comments','Reported_On','End_Date','latitude','longitude','Duration_Default','Duration_Hours']\n",
    "df2021=df2021[order]\n",
    "df2022=df2022[order]\n",
    "df2023=df2023[order]\n",
    "df2024=df2024[order]\n",
    "\n",
    "#Merge the dataframes together.\n",
    "df = pd.concat([df2021, df2022, df2023, df2024])\n",
    "\n",
    "#Export the merged dataframe to a csv file to create a master dataset\n",
    "#CSV is normally my default export file format.\n",
    "df.to_csv(\"kytc-closures-2021-2024-report_dataset.csv\", index=False) \n",
    "\n",
    "#Export to XLSX to make it easier to email coworkers.\n",
    "#Requires the openpyxl library to be installed.\n",
    "df.to_excel(\"kytc-closures-2021-2024-report_dataset.xlsx\", index=False) \n",
    "\n",
    "#Parquet is useful for big data and is a good format for data lakes.\n",
    "df.to_parquet(\"kytc-closures-2021-2024-report_dataset.parquet\", index=False) \n",
    "\n",
    "\n",
    "#Each data frame contains the following columns:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Visualizations (matplotlib)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantify the total count of road closures by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantify the total count of road closures by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantify the count of closures by individual roadways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantify the duration of closures by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantify the duration of closures by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantify the duration of closures by road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS:\n",
    "Map the closures on a geospacial map.<br>\n",
    "Possible methods include using folium or geopandas.<br>\n",
    "https://python-visualization.github.io/folium/latest/getting_started.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BONUS:  Perform the entire analysis in PowerBI and leave the file in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Feature: Check for PowerBI or Tableau files in the repo.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
